import json
import logging
from kafka import KafkaConsumer, KafkaProducer
from datetime import datetime, timedelta
from termcolor import colored
from pyfiglet import Figlet
from model_loader import predict
import time
from collections import deque, defaultdict
import threading
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from dataclasses import dataclass, asdict
from typing import Dict, Any, Optional, List
import pytz
import socket
import psutil
import statistics
from prometheus_client import start_http_server, Counter, Gauge, Histogram
import signal
import sys
import os
from pathlib import Path
from cryptography.fernet import Fernet
import hashlib

# ==================== Configuration ====================
class Config:
    # Kafka Configuration
    KAFKA_SERVERS = ['kafka1:9092', 'kafka2:9092', 'kafka3:9092']
    KAFKA_TOPIC = 'network-traffic'
    KAFKA_GROUP_ID = 'threat-detector-v2'
    KAFKA_ALERTS_TOPIC = 'security-alerts'
    
    # Model Configuration
    MODEL_PATHS = {
        'threat': '/secure/models/threat_detection_model_v3.pkl',
        'anomaly': '/secure/models/anomaly_model_v3.pkl'
    }
    
    # Thresholds
    THRESHOLDS = {
        'critical_threat': 0.9,
        'high_threat': 0.75,
        'medium_threat': 0.6,
        'anomaly': 0.85
    }
    
    # Alerting Configuration
    ALERT_THROTTLE_SECONDS = 300  # 5 minutes
    HEARTBEAT_INTERVAL = 60  # seconds
    METRICS_PORT = 9090
    MAX_MESSAGE_SIZE = 10485760  # 10MB
    
    # Security Configuration
    ENCRYPTION_KEY = os.getenv('ENCRYPTION_KEY', 'default_encryption_key_here')
    DATA_RETENTION_DAYS = 7
    
    # Email Configuration
    SMTP_SERVER = 'smtp.secure.com'
    SMTP_PORT = 587
    EMAIL_FROM = 'threat-detector@yourdomain.com'
    EMAIL_TO = ['security-team@yourdomain.com', 'soc@yourdomain.com']

# ==================== Data Classes ====================
@dataclass
class Alert:
    id: str
    type: str
    score: float
    timestamp: str
    source_ip: Optional[str] = None
    destination_ip: Optional[str] = None
    protocol: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    processed: bool = False

@dataclass
class SystemMetrics:
    cpu_usage: float
    memory_usage: float
    network_io: dict
    process_count: int
    timestamp: str

# ==================== Metrics Setup ====================
# Prometheus Metrics
MESSAGES_PROCESSED = Counter('threat_detector_messages_processed', 'Total messages processed')
ALERTS_GENERATED = Counter('threat_detector_alerts_generated', 'Alerts generated by type', ['alert_type'])
PROCESSING_TIME = Histogram('threat_detector_processing_time', 'Message processing time in seconds')
SYSTEM_METRICS = Gauge('threat_detector_system_metrics', 'System resource metrics', ['metric_type'])

# ==================== Utility Functions ====================
def generate_alert_id(data: dict) -> str:
    """Generate a unique ID for each alert based on its content"""
    hash_input = f"{data['source_ip']}-{data['destination_ip']}-{data.get('protocol', '')}-{time.time()}"
    return hashlib.sha256(hash_input.encode()).hexdigest()[:16]

def encrypt_data(data: str) -> str:
    """Encrypt sensitive data before storage/transmission"""
    cipher_suite = Fernet(Config.ENCRYPTION_KEY.encode())
    return cipher_suite.encrypt(data.encode()).decode()

def decrypt_data(encrypted_data: str) -> str:
    """Decrypt encrypted data"""
    cipher_suite = Fernet(Config.ENCRYPTION_KEY.encode())
    return cipher_suite.decrypt(encrypted_data.encode()).decode()

def get_system_metrics() -> SystemMetrics:
    """Collect comprehensive system metrics"""
    net_io = psutil.net_io_counters()
    return SystemMetrics(
        cpu_usage=psutil.cpu_percent(interval=1),
        memory_usage=psutil.virtual_memory().percent,
        network_io={
            'bytes_sent': net_io.bytes_sent,
            'bytes_recv': net_io.bytes_recv,
            'packets_sent': net_io.packets_sent,
            'packets_recv': net_io.packets_recv
        },
        process_count=len(psutil.pids()),
        timestamp=datetime.now(pytz.utc).isoformat()
    )

# ==================== Main Detector Class ====================
class ThreatDetector:
    def __init__(self):
        self.models = {}
        self.last_alert_time = {}
        self.alert_history = deque(maxlen=1000)
        self.ip_alert_counts = defaultdict(int)
        self.running = True
        self.message_count = 0
        self.processing_times = []
        self.kafka_producer = None
        self.hostname = socket.gethostname()
        self.start_time = datetime.now(pytz.utc)
        
        # Initialize components
        self.setup_logging()
        self.print_banner()
        self.load_models()
        self.init_kafka_producer()
        self.setup_signal_handlers()
        
        # Start monitoring threads
        self.start_heartbeat()
        self.start_metrics_monitor()
        start_http_server(Config.METRICS_PORT)

    def setup_logging(self):
        """Configure advanced logging with file rotation"""
        self.logger = logging.getLogger('threat_detector')
        self.logger.setLevel(logging.INFO)
        
        # Create logs directory if it doesn't exist
        Path('logs').mkdir(exist_ok=True)
        
        # File handler with rotation
        file_handler = logging.handlers.TimedRotatingFileHandler(
            'logs/threat_detector.log',
            when='midnight',
            backupCount=7
        )
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        
        # Console handler with colors
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(ColorFormatter())
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

    def print_banner(self):
        """Display system banner with version info"""
        f = Figlet(font='slant')
        print(colored(f.renderText('CYBER SHIELD'), 'cyan'))
        print(colored('='*60, 'blue'))
        print(colored(f'Advanced Threat Detection System v3.0\n', 'yellow'))
        print(colored(f'Host: {self.hostname} | Start Time: {self.start_time.isoformat()}\n', 'green'))
        print(colored('Listening for network traffic...\n', 'green'))

    def setup_signal_handlers(self):
        """Handle graceful shutdown on SIGINT/SIGTERM"""
        signal.signal(signal.SIGINT, self.graceful_shutdown)
        signal.signal(signal.SIGTERM, self.graceful_shutdown)

    def init_kafka_producer(self):
        """Initialize Kafka producer for sending alerts"""
        try:
            self.kafka_producer = KafkaProducer(
                bootstrap_servers=Config.KAFKA_SERVERS,
                value_serializer=lambda x: json.dumps(x).encode('utf-8'),
                max_request_size=Config.MAX_MESSAGE_SIZE,
                retries=5,
                acks='all'
            )
            self.logger.info("Kafka producer initialized successfully")
        except Exception as e:
            self.logger.error(f"Failed to initialize Kafka producer: {str(e)}")
            raise

    def load_models(self):
        """Load ML models with enhanced validation"""
        try:
            self.logger.info("Loading threat detection models...")
            
            # Load models with version checking
            self.models['threat'] = load_model(Config.MODEL_PATHS['threat'])
            self.models['anomaly'] = load_model(Config.MODEL_PATHS['anomaly'])
            
            # Verify model predictions
            test_input = [0.0] * 50  # Adjust based on expected feature size
            for model_name, model in self.models.items():
                prediction = predict(model, test_input)
                if not isinstance(prediction, (float, int)):
                    raise ValueError(f"Model {model_name} returned invalid prediction type")
            
            self.logger.info("Models loaded and validated successfully")
            print(colored("[SUCCESS] ", 'green') + "All models loaded and validated")
            
        except Exception as e:
            self.logger.critical(f"Model loading failed: {str(e)}")
            print(colored("[CRITICAL ERROR] ", 'red') + f"Model loading failed: {str(e)}")
            self.graceful_shutdown()
            sys.exit(1)

    def start_heartbeat(self):
        """Periodic system status updates"""
        def heartbeat():
            while self.running:
                try:
                    time.sleep(Config.HEARTBEAT_INTERVAL)
                    metrics = get_system_metrics()
                    
                    status = (
                        f"System Status | "
                        f"CPU: {metrics.cpu_usage}% | "
                        f"Mem: {metrics.memory_usage}% | "
                        f"Messages: {self.message_count} | "
                        f"Alerts: {len(self.alert_history)} | "
                        f"Avg Process Time: {statistics.mean(self.processing_times[-10:] if self.processing_times else 0):.3f}s"
                    )
                    
                    # Update Prometheus metrics
                    SYSTEM_METRICS.labels('cpu_usage').set(metrics.cpu_usage)
                    SYSTEM_METRICS.labels('memory_usage').set(metrics.memory_usage)
                    
                    print(colored(f"[HEARTBEAT] {datetime.now().isoformat()} - {status}", 'blue'))
                    self.logger.info(status)
                    
                except Exception as e:
                    self.logger.error(f"Heartbeat error: {str(e)}")

        threading.Thread(target=heartbeat, daemon=True, name="HeartbeatThread").start()

    def start_metrics_monitor(self):
        """Monitor and log system metrics periodically"""
        def monitor():
            while self.running:
                try:
                    time.sleep(60)  # Check every minute
                    metrics = get_system_metrics()
                    
                    # Log warning if resource usage is high
                    if metrics.cpu_usage > 80 or metrics.memory_usage > 80:
                        warning_msg = (
                            f"High resource usage - "
                            f"CPU: {metrics.cpu_usage}% | "
                            f"Memory: {metrics.memory_usage}%"
                        )
                        self.logger.warning(warning_msg)
                        
                except Exception as e:
                    self.logger.error(f"Metrics monitoring error: {str(e)}")

        threading.Thread(target=monitor, daemon=True, name="MetricsMonitor").start()

    def process_message(self, data: dict):
        """Process a single Kafka message with enhanced validation"""
        start_time = time.time()
        self.message_count += 1
        MESSAGES_PROCESSED.inc()
        
        try:
            # Validate message structure
            if not isinstance(data, dict) or 'features' not in data:
                raise ValueError("Invalid message format: missing 'features'")
                
            if not isinstance(data['features'], list) or len(data['features']) < 10:
                raise ValueError("Invalid features: must be list with at least 10 elements")
            
            # Extract and validate features
            features = [float(x) for x in data['features']]
            if any(not isinstance(x, float) for x in features):
                raise ValueError("All features must be numeric")
            
            # Extract metadata with defaults
            metadata = {
                'source_ip': data.get('source_ip', 'unknown'),
                'destination_ip': data.get('destination_ip', 'unknown'),
                'protocol': data.get('protocol', 'unknown'),
                'timestamp': data.get('timestamp', datetime.now(pytz.utc).isoformat()),
                'received_at': datetime.now(pytz.utc).isoformat(),
                'message_id': data.get('message_id', str(uuid.uuid4()))
            }
            
            # Make predictions
            with PROCESSING_TIME.time():
                threat_level = predict(self.models['threat'], features)
                anomaly_score = predict(self.models['anomaly'], features)
            
            # Evaluate threats
            self.evaluate_threat(threat_level, anomaly_score, metadata)
            
            # Log processing time
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            
            self.logger.debug(
                f"Processed message in {processing_time:.3f}s | "
                f"Threat: {threat_level:.3f} | "
                f"Anomaly: {anomaly_score:.3f} | "
                f"From: {metadata['source_ip']}"
            )
            
        except Exception as e:
            error_id = str(uuid.uuid4())
            self.logger.error(
                f"Error processing message (ID: {error_id}): {str(e)} | "
                f"Message: {json.dumps(data)[:200]}..."
            )
            print(colored(f"[ERROR {error_id}] Message processing failed: {str(e)}", 'red'))

    def evaluate_threat(self, threat_level: float, anomaly_score: float, metadata: dict):
        """Evaluate threat levels with enhanced logic"""
        timestamp = datetime.now(pytz.utc).isoformat()
        source_ip = metadata['source_ip']
        
        # Threat classification
        if threat_level > Config.THRESHOLDS['critical_threat']:
            alert_type = 'CRITICAL_THREAT'
            alert_color = 'red'
        elif threat_level > Config.THRESHOLDS['high_threat']:
            alert_type = 'HIGH_THREAT'
            alert_color = 'yellow'
        elif threat_level > Config.THRESHOLDS['medium_threat']:
            alert_type = 'MEDIUM_THREAT'
            alert_color = 'blue'
        else:
            alert_type = None
        
        # Create threat alert if needed
        if alert_type:
            alert = Alert(
                id=generate_alert_id(metadata),
                type=alert_type,
                score=threat_level,
                timestamp=timestamp,
                source_ip=source_ip,
                destination_ip=metadata['destination_ip'],
                protocol=metadata['protocol'],
                metadata=metadata
            )
            self.handle_alert(alert)
            ALERTS_GENERATED.labels(alert_type=alert_type).inc()
        
        # Anomaly detection
        if anomaly_score > Config.THRESHOLDS['anomaly']:
            alert = Alert(
                id=generate_alert_id(metadata),
                type='ANOMALY',
                score=anomaly_score,
                timestamp=timestamp,
                source_ip=source_ip,
                destination_ip=metadata['destination_ip'],
                protocol=metadata['protocol'],
                metadata=metadata
            )
            self.handle_alert(alert)
            ALERTS_GENERATED.labels(alert_type='ANOMALY').inc()
        
        # Update IP threat counters
        if alert_type in ('CRITICAL_THREAT', 'HIGH_THREAT'):
            self.ip_alert_counts[source_ip] += 1
            if self.ip_alert_counts[source_ip] > 10:
                self.logger.warning(f"Excessive alerts from IP: {source_ip} (count: {self.ip_alert_counts[source_ip]})")

    def handle_alert(self, alert: Alert):
        """Process and distribute alerts with enhanced logic"""
        # Throttle alerts of the same type from same source
        throttle_key = f"{alert.type}:{alert.source_ip}"
        last_alert = self.last_alert_time.get(throttle_key, 0)
        current_time = time.time()
        
        if current_time - last_alert < Config.ALERT_THROTTLE_SECONDS:
            self.logger.debug(f"Throttling {alert.type} alert from {alert.source_ip}")
            return
            
        self.last_alert_time[throttle_key] = current_time
        self.alert_history.append(alert)
        
        # Format alert message based on type
        alert_formats = {
            'CRITICAL_THREAT': ('ðŸš¨ CRITICAL THREAT DETECTED', 'red', True),
            'HIGH_THREAT': ('âš ï¸ HIGH THREAT DETECTED', 'yellow', True),
            'MEDIUM_THREAT': ('ðŸ”” MEDIUM THREAT DETECTED', 'blue', False),
            'ANOMALY': ('ðŸ” NETWORK ANOMALY', 'magenta', False)
        }
